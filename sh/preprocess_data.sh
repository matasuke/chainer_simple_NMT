python preprocess_tokens.py small_parallel_enja/train.ja data/ja_dataset.pickle --lang jp --tokenize
python preprocess_tokens.py small_parallel_enja/train.en data/en_dataset.pickle --lang en --tokenize
